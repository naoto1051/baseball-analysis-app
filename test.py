# ===============================
# âš¾ é‡çƒãƒ‡ãƒ¼ã‚¿åˆ†æWebã‚¢ãƒ—ãƒªï¼ˆPCA + ã‚¯ãƒ©ã‚¹ã‚¿ + å¯è¦–åŒ– + æ±ºå®šæœ¨ï¼‰
# ===============================

# ===============================
# ğŸ”§ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªèª­ã¿è¾¼ã¿
# ===============================
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.tree import DecisionTreeClassifier, plot_tree

# ===============================
# ğŸŒ ã‚¢ãƒ—ãƒªã‚¿ã‚¤ãƒˆãƒ«
# ===============================
st.title("âš¾ é‡çƒãƒ‡ãƒ¼ã‚¿åˆ†æã‚¢ãƒ—ãƒª")
st.markdown("""
PCAã«ã‚ˆã‚‹æ¬¡å…ƒåœ§ç¸®ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã€ã‚¯ãƒ©ã‚¹ã‚¿å¹³å‡å¯è¦–åŒ–ã€
ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã€PCAãƒã‚¤ãƒ—ãƒ­ãƒƒãƒˆã€æ±ºå®šæœ¨åˆ†æã‚’ä¸€å…ƒç®¡ç†ã€‚
""")

# ===============================
# ğŸ“¤ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ===============================
uploaded_file = st.file_uploader("Excelã¾ãŸã¯CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx","csv"])

if uploaded_file:
    # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
    if uploaded_file.name.endswith(".xlsx"):
        df = pd.read_excel(uploaded_file, sheet_name="Sheet1", engine="openpyxl")
    else:
        df = pd.read_csv(uploaded_file)

    st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿")
    st.dataframe(df.head())

    # ===============================
    # ğŸ”¹ åˆ†æã™ã‚‹ç‰¹å¾´é‡é¸æŠ
    # ===============================
    exclude_cols = ['No.', 'Name', 'Date']
    X_cols = [c for c in df.columns if c not in exclude_cols]
    selected_features = st.multiselect("åˆ†æã™ã‚‹ç‰¹å¾´é‡", X_cols, default=X_cols)

    if selected_features:
        # ===============================
        # ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
        # ===============================
        scaler = StandardScaler()
        X_std = scaler.fit_transform(df[selected_features])

        # ===============================
        # ğŸ“‰ PCAã«ã‚ˆã‚‹2æ¬¡å…ƒåœ§ç¸®
        # ===============================
        pca = PCA(n_components=2, random_state=42)
        pca_result = pca.fit_transform(X_std)
        df['PCA1'], df['PCA2'] = pca_result[:,0], pca_result[:,1]

        # ===============================
        # ğŸ§  KMeansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        # ===============================
        k = st.slider("ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’é¸æŠ", 2, 6, 3)
        kmeans = KMeans(n_clusters=k, random_state=42)
        df['Cluster'] = kmeans.fit_predict(df[['PCA1','PCA2']])

        # ===============================
        # ğŸ“Š PCAæ•£å¸ƒå›³ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿è‰²åˆ†ã‘ï¼‰
        # ===============================
        st.subheader("PCAæ•£å¸ƒå›³ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿è‰²åˆ†ã‘ï¼‰")
        plt.figure(figsize=(8,6))
        sns.scatterplot(data=df, x='PCA1', y='PCA2', hue='Cluster',
                        palette='viridis', s=100, edgecolor='black')
        for i in range(len(df)):
            plt.text(df.loc[i,'PCA1'], df.loc[i,'PCA2'], df.loc[i,'Name'],
                     fontsize=8, ha='center', va='center', color='black')
        st.pyplot(plt)

        # ===============================
        # ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿å¹³å‡ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼†ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
        # ===============================
        cluster_means = df.groupby('Cluster')[selected_features].mean()

        # æ£’ã‚°ãƒ©ãƒ•ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ï¼‰
        st.subheader("ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´å¹³å‡ï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰")
        plt.figure(figsize=(16,6))
        cluster_means.plot(kind='bar', rot=0, width=0.8)
        plt.ylabel('å¹³å‡ Zã‚¹ã‚³ã‚¢')
        plt.xlabel('ã‚¯ãƒ©ã‚¹ã‚¿')
        plt.title('ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´å¹³å‡å€¤')
        plt.legend(title='ç‰¹å¾´é‡', bbox_to_anchor=(1.02,1), loc='upper left')
        plt.grid(axis='y', linestyle='--', alpha=0.5)
        plt.tight_layout()
        st.pyplot(plt)

        # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        st.subheader("ã‚¯ãƒ©ã‚¹ã‚¿ Ã— ç‰¹å¾´é‡ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        plt.figure(figsize=(12,6))
        sns.heatmap(cluster_means.T, annot=True, fmt=".2f", cmap='RdYlBu_r', center=0)
        plt.title("ã‚¯ãƒ©ã‚¹ã‚¿ Ã— ç‰¹å¾´é‡ ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—")
        plt.tight_layout()
        st.pyplot(plt)

        # ===============================
        # ğŸ•¸ï¸ ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        # ===============================
        st.subheader("ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰")
        features = cluster_means.columns.tolist()
        num_vars = len(features)
        angles = np.linspace(0, 2*np.pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]

        colors = ['#1f77b4','#ff7f0e','#2ca02c','#d62728','#9467bd','#8c564b']
        plt.figure(figsize=(8,8))
        for i, label in enumerate(cluster_means.index):
            values = cluster_means.loc[label].tolist()
            values += values[:1]
            plt.polar(angles, values, label=f"ã‚¯ãƒ©ã‚¹ã‚¿{label}", color=colors[i], linewidth=2)
            plt.fill(angles, values, alpha=0.15, color=colors[i])
        plt.xticks(angles[:-1], features, fontsize=10)
        plt.title("ã‚¯ãƒ©ã‚¹ã‚¿ã”ã¨ã®ç‰¹å¾´æ¯”è¼ƒï¼ˆãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰", pad=20)
        plt.legend(loc='upper right', bbox_to_anchor=(1.3,1.1))
        plt.tight_layout()
        st.pyplot(plt)

        # ===============================
        # ğŸŒ² æ±ºå®šæœ¨ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡
        # ===============================
        st.subheader("æ±ºå®šæœ¨ã«ã‚ˆã‚‹ã‚¯ãƒ©ã‚¹ã‚¿åˆ†é¡")
        X = df[selected_features]
        y = df['Cluster']
        dt = DecisionTreeClassifier(max_depth=4, random_state=42)
        dt.fit(X, y)

        y_pred = dt.predict(X)
        acc = (y_pred==y).mean()
        st.write(f"æ±ºå®šæœ¨ã®å­¦ç¿’ç²¾åº¦: {acc:.3f}")

        plt.figure(figsize=(20,12))
        plot_tree(dt, feature_names=selected_features,
                  class_names=[f'ã‚¯ãƒ©ã‚¹ã‚¿{i}' for i in range(k)],
                  filled=True, rounded=True)
        st.pyplot(plt)
